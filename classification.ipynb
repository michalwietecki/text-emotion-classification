{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfed54bf",
   "metadata": {},
   "source": [
    "## Data importing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913b2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb618add",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de053f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah for coupons!   Found this place randomly ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i still love to feel a gentle breeze and hear ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal, fama devido ao programa de tv. A sobre...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im feeling a little less jaded</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have never shaken the feeling of ferocious p...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i figure my family loves us no matter what but...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i feel uncertain i will raise my</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i was feeling relaxed and quite comfortable at...</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i feel like ive lost everything and everyone</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i feel this way is probably because i am dumb ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    emotion\n",
       "0  Yeah for coupons!   Found this place randomly ...    neutral\n",
       "1  i still love to feel a gentle breeze and hear ...  happiness\n",
       "2  Normal, fama devido ao programa de tv. A sobre...    neutral\n",
       "3                     im feeling a little less jaded    sadness\n",
       "4  i have never shaken the feeling of ferocious p...       hate\n",
       "5  i figure my family loves us no matter what but...    sadness\n",
       "6                   i feel uncertain i will raise my      worry\n",
       "7  i was feeling relaxed and quite comfortable at...        fun\n",
       "8       i feel like ive lost everything and everyone    sadness\n",
       "9  i feel this way is probably because i am dumb ...    sadness"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfb338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc124150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness    1468\n",
       "neutral      1292\n",
       "worry        1222\n",
       "fun          1157\n",
       "sadness      1146\n",
       "hate         1143\n",
       "surprise      572\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() #relatively balanced dataset, the surpise emotion is the least populated one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3870362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=52\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49c230e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68e6c379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a48f1",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce19160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_test_enc = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45077313-ba62-4c08-8797-3b963f0e949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train_enc\n",
    "# y_test = y_test_enc\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0335d",
   "metadata": {},
   "source": [
    "## First vectorization methods and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b336f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32df3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0930fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(pipeline):\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"\\n Model Performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a70ea",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes with various vectorization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99422bb1",
   "metadata": {},
   "source": [
    "## BOW - bag of words\n",
    "Counts the number of times each word appears in a document.\n",
    "<li>lots of dimensions</li>\n",
    "<li>Simple, easy to understand.</li>\n",
    "<li>ignores word order, context, and meaning</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b807f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  14101\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.84      0.55      0.66       231\n",
      "   happiness       0.58      0.95      0.72       294\n",
      "        hate       0.80      0.68      0.73       229\n",
      "     neutral       0.78      1.00      0.88       258\n",
      "     sadness       0.85      0.59      0.70       229\n",
      "    surprise       0.93      0.12      0.22       115\n",
      "       worry       0.71      0.79      0.75       244\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.79      0.67      0.66      1600\n",
      "weighted avg       0.77      0.72      0.70      1600\n",
      "\n",
      "Accuracy: 0.724375\n"
     ]
    }
   ],
   "source": [
    "bow_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "num_features = len(bow_pipeline.named_steps['vectorizer'].vocabulary_)\n",
    "print(\"this many features were found: \", num_features)\n",
    "\n",
    "model_evaluation(bow_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2827f",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "Considers sequences of n words to capture more context.\n",
    "<li>Captures simple word combinations\n",
    "<li>High dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97a6cea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  285115\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.58      0.27      0.37       231\n",
      "   happiness       0.45      0.68      0.54       294\n",
      "        hate       0.56      0.36      0.44       229\n",
      "     neutral       0.50      1.00      0.67       258\n",
      "     sadness       0.54      0.35      0.42       229\n",
      "    surprise       0.80      0.17      0.29       115\n",
      "       worry       0.56      0.49      0.52       244\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.57      0.48      0.46      1600\n",
      "weighted avg       0.55      0.51      0.48      1600\n",
      "\n",
      "Accuracy: 0.514375\n"
     ]
    }
   ],
   "source": [
    "bow_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(2, 3))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "\n",
    "num_features = len(bow_pipeline.named_steps['vectorizer'].vocabulary_)\n",
    "print(\"this many features were found: \", num_features)\n",
    "\n",
    "model_evaluation(bow_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709be5d-5a17-4745-8903-c7a622329a72",
   "metadata": {},
   "source": [
    "### experimenting with ngram_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9977d151-bfda-4a8e-99f8-a1431e0bd6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ngram_range=(1,1)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.84      0.55      0.66       231\n",
      "   happiness       0.58      0.95      0.72       294\n",
      "        hate       0.80      0.68      0.73       229\n",
      "     neutral       0.78      1.00      0.88       258\n",
      "     sadness       0.85      0.59      0.70       229\n",
      "    surprise       0.93      0.12      0.22       115\n",
      "       worry       0.71      0.79      0.75       244\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.79      0.67      0.66      1600\n",
      "weighted avg       0.77      0.72      0.70      1600\n",
      "\n",
      "Accuracy: 0.724375\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(1,2)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.87      0.30      0.45       231\n",
      "   happiness       0.50      0.81      0.62       294\n",
      "        hate       0.80      0.45      0.58       229\n",
      "     neutral       0.43      1.00      0.60       258\n",
      "     sadness       0.84      0.40      0.54       229\n",
      "    surprise       0.82      0.08      0.14       115\n",
      "       worry       0.72      0.60      0.65       244\n",
      "\n",
      "    accuracy                           0.57      1600\n",
      "   macro avg       0.71      0.52      0.51      1600\n",
      "weighted avg       0.69      0.57      0.55      1600\n",
      "\n",
      "Accuracy: 0.57125\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(1,3)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.84      0.25      0.39       231\n",
      "   happiness       0.51      0.67      0.58       294\n",
      "        hate       0.82      0.39      0.53       229\n",
      "     neutral       0.34      1.00      0.50       258\n",
      "     sadness       0.87      0.35      0.50       229\n",
      "    surprise       0.82      0.08      0.14       115\n",
      "       worry       0.72      0.50      0.59       244\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.70      0.46      0.46      1600\n",
      "weighted avg       0.68      0.51      0.49      1600\n",
      "\n",
      "Accuracy: 0.508125\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(1,4)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.88      0.23      0.36       231\n",
      "   happiness       0.52      0.61      0.56       294\n",
      "        hate       0.80      0.36      0.50       229\n",
      "     neutral       0.30      1.00      0.46       258\n",
      "     sadness       0.87      0.30      0.45       229\n",
      "    surprise       0.80      0.07      0.13       115\n",
      "       worry       0.71      0.44      0.55       244\n",
      "\n",
      "    accuracy                           0.47      1600\n",
      "   macro avg       0.70      0.43      0.43      1600\n",
      "weighted avg       0.68      0.47      0.46      1600\n",
      "\n",
      "Accuracy: 0.473125\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(1,5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.88      0.22      0.35       231\n",
      "   happiness       0.53      0.58      0.55       294\n",
      "        hate       0.83      0.35      0.50       229\n",
      "     neutral       0.29      1.00      0.45       258\n",
      "     sadness       0.88      0.30      0.45       229\n",
      "    surprise       0.80      0.07      0.13       115\n",
      "       worry       0.71      0.43      0.54       244\n",
      "\n",
      "    accuracy                           0.46      1600\n",
      "   macro avg       0.70      0.42      0.42      1600\n",
      "weighted avg       0.68      0.46      0.45      1600\n",
      "\n",
      "Accuracy: 0.46375\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(2,2)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.51      0.24      0.33       231\n",
      "   happiness       0.45      0.73      0.56       294\n",
      "        hate       0.59      0.38      0.47       229\n",
      "     neutral       0.55      1.00      0.71       258\n",
      "     sadness       0.53      0.36      0.43       229\n",
      "    surprise       0.83      0.13      0.23       115\n",
      "       worry       0.58      0.53      0.56       244\n",
      "\n",
      "    accuracy                           0.53      1600\n",
      "   macro avg       0.58      0.48      0.47      1600\n",
      "weighted avg       0.56      0.53      0.49      1600\n",
      "\n",
      "Accuracy: 0.526875\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(2,3)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.58      0.27      0.37       231\n",
      "   happiness       0.45      0.68      0.54       294\n",
      "        hate       0.56      0.36      0.44       229\n",
      "     neutral       0.50      1.00      0.67       258\n",
      "     sadness       0.54      0.35      0.42       229\n",
      "    surprise       0.80      0.17      0.29       115\n",
      "       worry       0.56      0.49      0.52       244\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.57      0.48      0.46      1600\n",
      "weighted avg       0.55      0.51      0.48      1600\n",
      "\n",
      "Accuracy: 0.514375\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(2,4)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.58      0.28      0.37       231\n",
      "   happiness       0.45      0.67      0.54       294\n",
      "        hate       0.56      0.35      0.43       229\n",
      "     neutral       0.49      1.00      0.66       258\n",
      "     sadness       0.56      0.35      0.43       229\n",
      "    surprise       0.81      0.18      0.30       115\n",
      "       worry       0.56      0.48      0.51       244\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.57      0.47      0.46      1600\n",
      "weighted avg       0.55      0.51      0.48      1600\n",
      "\n",
      "Accuracy: 0.51\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(2,5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.58      0.27      0.37       231\n",
      "   happiness       0.44      0.66      0.53       294\n",
      "        hate       0.57      0.34      0.43       229\n",
      "     neutral       0.48      1.00      0.65       258\n",
      "     sadness       0.56      0.34      0.43       229\n",
      "    surprise       0.81      0.18      0.30       115\n",
      "       worry       0.56      0.48      0.52       244\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.57      0.47      0.46      1600\n",
      "weighted avg       0.55      0.51      0.48      1600\n",
      "\n",
      "Accuracy: 0.50625\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(3,3)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.37      0.19      0.25       231\n",
      "   happiness       0.31      0.64      0.42       294\n",
      "        hate       0.38      0.23      0.29       229\n",
      "     neutral       0.61      0.97      0.75       258\n",
      "     sadness       0.33      0.17      0.22       229\n",
      "    surprise       0.65      0.13      0.22       115\n",
      "       worry       0.43      0.32      0.37       244\n",
      "\n",
      "    accuracy                           0.42      1600\n",
      "   macro avg       0.44      0.38      0.36      1600\n",
      "weighted avg       0.42      0.42      0.38      1600\n",
      "\n",
      "Accuracy: 0.418125\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(3,4)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.35      0.21      0.26       231\n",
      "   happiness       0.31      0.62      0.42       294\n",
      "        hate       0.37      0.23      0.28       229\n",
      "     neutral       0.62      0.97      0.76       258\n",
      "     sadness       0.33      0.17      0.23       229\n",
      "    surprise       0.61      0.15      0.24       115\n",
      "       worry       0.42      0.32      0.36       244\n",
      "\n",
      "    accuracy                           0.42      1600\n",
      "   macro avg       0.43      0.38      0.36      1600\n",
      "weighted avg       0.42      0.42      0.38      1600\n",
      "\n",
      "Accuracy: 0.418125\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(3,5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.35      0.21      0.26       231\n",
      "   happiness       0.31      0.62      0.42       294\n",
      "        hate       0.37      0.23      0.28       229\n",
      "     neutral       0.62      0.97      0.76       258\n",
      "     sadness       0.32      0.17      0.23       229\n",
      "    surprise       0.61      0.15      0.24       115\n",
      "       worry       0.42      0.32      0.36       244\n",
      "\n",
      "    accuracy                           0.42      1600\n",
      "   macro avg       0.43      0.38      0.36      1600\n",
      "weighted avg       0.41      0.42      0.38      1600\n",
      "\n",
      "Accuracy: 0.4175\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(4,4)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.33      0.09      0.14       231\n",
      "   happiness       0.22      0.81      0.34       294\n",
      "        hate       0.31      0.07      0.11       229\n",
      "     neutral       0.74      0.80      0.77       258\n",
      "     sadness       0.14      0.03      0.05       229\n",
      "    surprise       0.38      0.03      0.05       115\n",
      "       worry       0.42      0.10      0.17       244\n",
      "\n",
      "    accuracy                           0.32      1600\n",
      "   macro avg       0.36      0.27      0.23      1600\n",
      "weighted avg       0.36      0.32      0.26      1600\n",
      "\n",
      "Accuracy: 0.321875\n",
      "\n",
      "\n",
      "\n",
      "for ngram_range=(4,5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.34      0.10      0.15       231\n",
      "   happiness       0.22      0.81      0.34       294\n",
      "        hate       0.29      0.06      0.10       229\n",
      "     neutral       0.74      0.80      0.77       258\n",
      "     sadness       0.14      0.03      0.05       229\n",
      "    surprise       0.33      0.03      0.05       115\n",
      "       worry       0.41      0.10      0.16       244\n",
      "\n",
      "    accuracy                           0.32      1600\n",
      "   macro avg       0.35      0.27      0.23      1600\n",
      "weighted avg       0.36      0.32      0.26      1600\n",
      "\n",
      "Accuracy: 0.321875\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    for j in range(1,6):\n",
    "        if i > j:\n",
    "            continue\n",
    "        bow_pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer(ngram_range=(i, j))),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ])\n",
    "        \n",
    "        bow_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"for ngram_range=({i},{j})\")\n",
    "        model_evaluation(bow_pipeline)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2baf07-f106-4e9e-b509-5ab6b67cc227",
   "metadata": {},
   "source": [
    "the longer the sequence the worse the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef4af4-1b33-4a1a-8e66-198aef9f8857",
   "metadata": {},
   "source": [
    "### experimenting with max_df/min_df argument \n",
    "ignore terms that have a document frequency strictly higher/lower than the given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "514693a1-a7fc-4112-bc3e-2acbc82d8850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.1,0.5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.20      0.06      0.09       231\n",
      "   happiness       0.23      0.43      0.30       294\n",
      "        hate       0.19      0.09      0.12       229\n",
      "     neutral       0.53      0.93      0.67       258\n",
      "     sadness       0.19      0.11      0.14       229\n",
      "    surprise       0.25      0.01      0.02       115\n",
      "       worry       0.22      0.25      0.24       244\n",
      "\n",
      "    accuracy                           0.31      1600\n",
      "   macro avg       0.26      0.27      0.23      1600\n",
      "weighted avg       0.26      0.31      0.25      1600\n",
      "\n",
      "Accuracy: 0.30625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.2,0.5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.24      0.05      0.08       231\n",
      "   happiness       0.23      0.54      0.32       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.48      0.93      0.64       258\n",
      "     sadness       0.25      0.06      0.10       229\n",
      "    surprise       1.00      0.01      0.02       115\n",
      "       worry       0.21      0.26      0.23       244\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.35      0.26      0.20      1600\n",
      "weighted avg       0.30      0.30      0.22      1600\n",
      "\n",
      "Accuracy: 0.30375\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.3,0.5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.14      0.00      0.01       231\n",
      "   happiness       0.19      0.58      0.29       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.42      0.72      0.53       258\n",
      "     sadness       0.00      0.00      0.00       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.18      0.17       244\n",
      "\n",
      "    accuracy                           0.25      1600\n",
      "   macro avg       0.13      0.21      0.14      1600\n",
      "weighted avg       0.15      0.25      0.17      1600\n",
      "\n",
      "Accuracy: 0.250625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.4,0.5)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.00      0.00      0.00       231\n",
      "   happiness       0.19      0.69      0.30       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.41      0.67      0.51       258\n",
      "     sadness       0.00      0.00      0.00       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.08      0.11       244\n",
      "\n",
      "    accuracy                           0.25      1600\n",
      "   macro avg       0.11      0.21      0.13      1600\n",
      "weighted avg       0.13      0.25      0.15      1600\n",
      "\n",
      "Accuracy: 0.246875\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.1,0.6)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.20      0.09      0.12       231\n",
      "   happiness       0.25      0.54      0.34       294\n",
      "        hate       0.19      0.09      0.12       229\n",
      "     neutral       0.86      0.96      0.91       258\n",
      "     sadness       0.20      0.15      0.17       229\n",
      "    surprise       0.11      0.01      0.02       115\n",
      "       worry       0.21      0.25      0.23       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.29      0.30      0.27      1600\n",
      "weighted avg       0.31      0.34      0.31      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.2,0.6)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.17      0.05      0.07       231\n",
      "   happiness       0.24      0.65      0.35       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.87      0.95      0.91       258\n",
      "     sadness       0.26      0.08      0.12       229\n",
      "    surprise       0.40      0.02      0.03       115\n",
      "       worry       0.21      0.31      0.25       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.31      0.29      0.25      1600\n",
      "weighted avg       0.31      0.34      0.28      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.3,0.6)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.25      0.01      0.02       231\n",
      "   happiness       0.21      0.65      0.31       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.53      0.92      0.68       258\n",
      "     sadness       0.09      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.14      0.15       244\n",
      "\n",
      "    accuracy                           0.29      1600\n",
      "   macro avg       0.18      0.25      0.17      1600\n",
      "weighted avg       0.20      0.29      0.19      1600\n",
      "\n",
      "Accuracy: 0.291875\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.4,0.6)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.00      0.00      0.00       231\n",
      "   happiness       0.21      0.72      0.33       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.58      0.92      0.71       258\n",
      "     sadness       0.25      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.13      0.14       244\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.17      0.25      0.17      1600\n",
      "weighted avg       0.19      0.30      0.20      1600\n",
      "\n",
      "Accuracy: 0.300625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.1,0.7)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.20      0.09      0.12       231\n",
      "   happiness       0.25      0.54      0.34       294\n",
      "        hate       0.19      0.09      0.12       229\n",
      "     neutral       0.86      0.96      0.91       258\n",
      "     sadness       0.20      0.15      0.17       229\n",
      "    surprise       0.11      0.01      0.02       115\n",
      "       worry       0.21      0.25      0.23       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.29      0.30      0.27      1600\n",
      "weighted avg       0.31      0.34      0.31      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.2,0.7)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.17      0.05      0.07       231\n",
      "   happiness       0.24      0.65      0.35       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.87      0.95      0.91       258\n",
      "     sadness       0.26      0.08      0.12       229\n",
      "    surprise       0.40      0.02      0.03       115\n",
      "       worry       0.21      0.31      0.25       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.31      0.29      0.25      1600\n",
      "weighted avg       0.31      0.34      0.28      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.3,0.7)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.25      0.01      0.02       231\n",
      "   happiness       0.21      0.65      0.31       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.53      0.92      0.68       258\n",
      "     sadness       0.09      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.14      0.15       244\n",
      "\n",
      "    accuracy                           0.29      1600\n",
      "   macro avg       0.18      0.25      0.17      1600\n",
      "weighted avg       0.20      0.29      0.19      1600\n",
      "\n",
      "Accuracy: 0.291875\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.4,0.7)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.00      0.00      0.00       231\n",
      "   happiness       0.21      0.72      0.33       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.58      0.92      0.71       258\n",
      "     sadness       0.25      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.13      0.14       244\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.17      0.25      0.17      1600\n",
      "weighted avg       0.19      0.30      0.20      1600\n",
      "\n",
      "Accuracy: 0.300625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.1,0.8)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.20      0.09      0.12       231\n",
      "   happiness       0.25      0.54      0.34       294\n",
      "        hate       0.19      0.09      0.12       229\n",
      "     neutral       0.86      0.96      0.91       258\n",
      "     sadness       0.20      0.15      0.17       229\n",
      "    surprise       0.11      0.01      0.02       115\n",
      "       worry       0.21      0.25      0.23       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.29      0.30      0.27      1600\n",
      "weighted avg       0.31      0.34      0.31      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.2,0.8)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.17      0.05      0.07       231\n",
      "   happiness       0.24      0.65      0.35       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.87      0.95      0.91       258\n",
      "     sadness       0.26      0.08      0.12       229\n",
      "    surprise       0.40      0.02      0.03       115\n",
      "       worry       0.21      0.31      0.25       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.31      0.29      0.25      1600\n",
      "weighted avg       0.31      0.34      0.28      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.3,0.8)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.25      0.01      0.02       231\n",
      "   happiness       0.21      0.65      0.31       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.53      0.92      0.68       258\n",
      "     sadness       0.09      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.14      0.15       244\n",
      "\n",
      "    accuracy                           0.29      1600\n",
      "   macro avg       0.18      0.25      0.17      1600\n",
      "weighted avg       0.20      0.29      0.19      1600\n",
      "\n",
      "Accuracy: 0.291875\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.4,0.8)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.00      0.00      0.00       231\n",
      "   happiness       0.21      0.72      0.33       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.58      0.92      0.71       258\n",
      "     sadness       0.25      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.13      0.14       244\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.17      0.25      0.17      1600\n",
      "weighted avg       0.19      0.30      0.20      1600\n",
      "\n",
      "Accuracy: 0.300625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.1,0.9)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.20      0.09      0.12       231\n",
      "   happiness       0.25      0.54      0.34       294\n",
      "        hate       0.19      0.09      0.12       229\n",
      "     neutral       0.86      0.96      0.91       258\n",
      "     sadness       0.20      0.15      0.17       229\n",
      "    surprise       0.11      0.01      0.02       115\n",
      "       worry       0.21      0.25      0.23       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.29      0.30      0.27      1600\n",
      "weighted avg       0.31      0.34      0.31      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.2,0.9)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.17      0.05      0.07       231\n",
      "   happiness       0.24      0.65      0.35       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.87      0.95      0.91       258\n",
      "     sadness       0.26      0.08      0.12       229\n",
      "    surprise       0.40      0.02      0.03       115\n",
      "       worry       0.21      0.31      0.25       244\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.31      0.29      0.25      1600\n",
      "weighted avg       0.31      0.34      0.28      1600\n",
      "\n",
      "Accuracy: 0.340625\n",
      "\n",
      "\n",
      "\n",
      "for min_df,max_df=(0.3,0.9)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.25      0.01      0.02       231\n",
      "   happiness       0.21      0.65      0.31       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.53      0.92      0.68       258\n",
      "     sadness       0.09      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.14      0.15       244\n",
      "\n",
      "    accuracy                           0.29      1600\n",
      "   macro avg       0.18      0.25      0.17      1600\n",
      "weighted avg       0.20      0.29      0.19      1600\n",
      "\n",
      "Accuracy: 0.291875\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_df,max_df=(0.4,0.9)\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.00      0.00      0.00       231\n",
      "   happiness       0.21      0.72      0.33       294\n",
      "        hate       0.00      0.00      0.00       229\n",
      "     neutral       0.58      0.92      0.71       258\n",
      "     sadness       0.25      0.00      0.01       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.16      0.13      0.14       244\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.17      0.25      0.17      1600\n",
      "weighted avg       0.19      0.30      0.20      1600\n",
      "\n",
      "Accuracy: 0.300625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for max_ in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    for min_ in [0.1,0.2,0.3,0.4]:\n",
    "        bow_pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer(ngram_range=(1, 1), min_df=min_, max_df=max_)),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ])\n",
    "        \n",
    "        bow_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"for min_df,max_df=({min_},{max_})\")\n",
    "        model_evaluation(bow_pipeline)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80dea7-7c2e-4256-8663-6c6c4a02d97d",
   "metadata": {},
   "source": [
    "changing those parameters decreases the performance as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd990c-5562-4fe0-acf4-ee6bedb8a12e",
   "metadata": {},
   "source": [
    "### experimenting with max_features argument\n",
    "only consider the top max_features ordered by term frequency <br>\n",
    "for ngram_range(1,1) we found 14101 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c7827b3-93f3-455d-a67d-a7d6cea80466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for max_fearures=1000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.51      0.46      0.49       231\n",
      "   happiness       0.67      0.82      0.74       294\n",
      "        hate       0.62      0.54      0.57       229\n",
      "     neutral       0.98      0.99      0.98       258\n",
      "     sadness       0.41      0.40      0.40       229\n",
      "    surprise       0.79      0.61      0.69       115\n",
      "       worry       0.61      0.65      0.63       244\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.65      0.64      0.64      1600\n",
      "weighted avg       0.65      0.65      0.65      1600\n",
      "\n",
      "Accuracy: 0.653125\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=2000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.72      0.64      0.68       231\n",
      "   happiness       0.71      0.91      0.80       294\n",
      "        hate       0.78      0.75      0.76       229\n",
      "     neutral       0.98      0.99      0.98       258\n",
      "     sadness       0.75      0.60      0.67       229\n",
      "    surprise       0.86      0.55      0.67       115\n",
      "       worry       0.68      0.79      0.73       244\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.78      0.75      0.76      1600\n",
      "weighted avg       0.78      0.77      0.77      1600\n",
      "\n",
      "Accuracy: 0.77125\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=3000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.76      0.69      0.72       231\n",
      "   happiness       0.72      0.91      0.81       294\n",
      "        hate       0.77      0.76      0.76       229\n",
      "     neutral       0.98      0.99      0.98       258\n",
      "     sadness       0.80      0.67      0.73       229\n",
      "    surprise       0.89      0.50      0.64       115\n",
      "       worry       0.71      0.81      0.76       244\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.81      0.76      0.77      1600\n",
      "weighted avg       0.80      0.79      0.79      1600\n",
      "\n",
      "Accuracy: 0.790625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=4000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.77      0.69      0.73       231\n",
      "   happiness       0.72      0.91      0.80       294\n",
      "        hate       0.76      0.76      0.76       229\n",
      "     neutral       0.97      0.99      0.98       258\n",
      "     sadness       0.82      0.70      0.75       229\n",
      "    surprise       0.85      0.39      0.54       115\n",
      "       worry       0.71      0.80      0.75       244\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.80      0.75      0.76      1600\n",
      "weighted avg       0.79      0.79      0.78      1600\n",
      "\n",
      "Accuracy: 0.7875\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=5000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.78      0.67      0.72       231\n",
      "   happiness       0.70      0.93      0.80       294\n",
      "        hate       0.77      0.76      0.77       229\n",
      "     neutral       0.97      0.99      0.98       258\n",
      "     sadness       0.82      0.70      0.75       229\n",
      "    surprise       0.88      0.32      0.47       115\n",
      "       worry       0.70      0.81      0.75       244\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.80      0.74      0.75      1600\n",
      "weighted avg       0.79      0.78      0.78      1600\n",
      "\n",
      "Accuracy: 0.78375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=6000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.79      0.66      0.72       231\n",
      "   happiness       0.68      0.95      0.80       294\n",
      "        hate       0.77      0.75      0.76       229\n",
      "     neutral       0.97      0.99      0.98       258\n",
      "     sadness       0.82      0.69      0.75       229\n",
      "    surprise       0.91      0.27      0.42       115\n",
      "       worry       0.70      0.81      0.75       244\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.81      0.73      0.74      1600\n",
      "weighted avg       0.80      0.78      0.77      1600\n",
      "\n",
      "Accuracy: 0.779375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=7000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.78      0.65      0.70       231\n",
      "   happiness       0.66      0.95      0.78       294\n",
      "        hate       0.77      0.75      0.76       229\n",
      "     neutral       0.94      0.99      0.97       258\n",
      "     sadness       0.84      0.67      0.75       229\n",
      "    surprise       0.90      0.23      0.36       115\n",
      "       worry       0.69      0.80      0.74       244\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.80      0.72      0.72      1600\n",
      "weighted avg       0.79      0.77      0.76      1600\n",
      "\n",
      "Accuracy: 0.76875\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=8000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.78      0.63      0.70       231\n",
      "   happiness       0.65      0.95      0.77       294\n",
      "        hate       0.78      0.74      0.76       229\n",
      "     neutral       0.92      1.00      0.96       258\n",
      "     sadness       0.83      0.66      0.73       229\n",
      "    surprise       0.92      0.21      0.34       115\n",
      "       worry       0.70      0.82      0.75       244\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.80      0.71      0.72      1600\n",
      "weighted avg       0.79      0.77      0.75      1600\n",
      "\n",
      "Accuracy: 0.765625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=9000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.79      0.61      0.69       231\n",
      "   happiness       0.63      0.95      0.75       294\n",
      "        hate       0.79      0.73      0.76       229\n",
      "     neutral       0.90      1.00      0.95       258\n",
      "     sadness       0.83      0.64      0.72       229\n",
      "    surprise       0.92      0.20      0.33       115\n",
      "       worry       0.71      0.81      0.75       244\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.80      0.70      0.71      1600\n",
      "weighted avg       0.78      0.76      0.74      1600\n",
      "\n",
      "Accuracy: 0.75625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=10000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.80      0.59      0.68       231\n",
      "   happiness       0.62      0.95      0.75       294\n",
      "        hate       0.78      0.72      0.75       229\n",
      "     neutral       0.87      1.00      0.93       258\n",
      "     sadness       0.84      0.64      0.72       229\n",
      "    surprise       0.92      0.20      0.33       115\n",
      "       worry       0.71      0.80      0.76       244\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.79      0.70      0.70      1600\n",
      "weighted avg       0.78      0.75      0.74      1600\n",
      "\n",
      "Accuracy: 0.75125\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=11000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.80      0.58      0.67       231\n",
      "   happiness       0.62      0.95      0.75       294\n",
      "        hate       0.78      0.70      0.74       229\n",
      "     neutral       0.84      1.00      0.91       258\n",
      "     sadness       0.84      0.63      0.72       229\n",
      "    surprise       0.91      0.17      0.29       115\n",
      "       worry       0.71      0.79      0.75       244\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.78      0.69      0.69      1600\n",
      "weighted avg       0.77      0.74      0.73      1600\n",
      "\n",
      "Accuracy: 0.74375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=12000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.82      0.57      0.67       231\n",
      "   happiness       0.60      0.96      0.74       294\n",
      "        hate       0.78      0.70      0.74       229\n",
      "     neutral       0.83      1.00      0.90       258\n",
      "     sadness       0.85      0.61      0.71       229\n",
      "    surprise       0.90      0.17      0.28       115\n",
      "       worry       0.71      0.80      0.75       244\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.79      0.68      0.69      1600\n",
      "weighted avg       0.77      0.74      0.72      1600\n",
      "\n",
      "Accuracy: 0.739375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=13000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.83      0.56      0.67       231\n",
      "   happiness       0.59      0.95      0.73       294\n",
      "        hate       0.78      0.68      0.73       229\n",
      "     neutral       0.80      1.00      0.89       258\n",
      "     sadness       0.85      0.60      0.70       229\n",
      "    surprise       0.93      0.12      0.22       115\n",
      "       worry       0.71      0.80      0.75       244\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.79      0.67      0.67      1600\n",
      "weighted avg       0.77      0.73      0.71      1600\n",
      "\n",
      "Accuracy: 0.729375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=14000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.84      0.55      0.66       231\n",
      "   happiness       0.57      0.95      0.72       294\n",
      "        hate       0.80      0.68      0.73       229\n",
      "     neutral       0.79      1.00      0.88       258\n",
      "     sadness       0.85      0.59      0.70       229\n",
      "    surprise       0.93      0.12      0.22       115\n",
      "       worry       0.71      0.79      0.75       244\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.79      0.67      0.67      1600\n",
      "weighted avg       0.77      0.72      0.70      1600\n",
      "\n",
      "Accuracy: 0.725\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for features in [k*1000 for k in [1,2,3,4,5,6,7,8,9,10,11,12,13,14]]:\n",
    "    bow_pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1, 1), max_features = features)),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    bow_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"for max_fearures={features}\")\n",
    "    model_evaluation(bow_pipeline)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f5a56-5c67-4f1e-9602-3997a08c82df",
   "metadata": {},
   "source": [
    "best for 3000 out of around 14000 features, accuracy = 0,79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3ca8e-081b-4e65-81a8-ea16fd58c91a",
   "metadata": {},
   "source": [
    "let's now see how many features are found in ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87b1e2d4-60a0-4ad5-94cd-36e07b0fbbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  118489\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bow_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "num_features = len(bow_pipeline.named_steps['vectorizer'].vocabulary_)\n",
    "print(\"this many features were found: \", num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f9134ad-8599-4537-be39-5bef689445a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for max_fearures=3000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.53      0.46      0.49       231\n",
      "   happiness       0.67      0.83      0.74       294\n",
      "        hate       0.63      0.64      0.64       229\n",
      "     neutral       0.95      0.99      0.97       258\n",
      "     sadness       0.51      0.45      0.47       229\n",
      "    surprise       0.78      0.49      0.60       115\n",
      "       worry       0.63      0.68      0.65       244\n",
      "\n",
      "    accuracy                           0.67      1600\n",
      "   macro avg       0.67      0.65      0.65      1600\n",
      "weighted avg       0.67      0.67      0.66      1600\n",
      "\n",
      "Accuracy: 0.67125\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=10000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.68      0.57      0.62       231\n",
      "   happiness       0.64      0.91      0.75       294\n",
      "        hate       0.68      0.66      0.67       229\n",
      "     neutral       0.95      0.99      0.97       258\n",
      "     sadness       0.68      0.59      0.63       229\n",
      "    surprise       0.86      0.33      0.48       115\n",
      "       worry       0.70      0.74      0.72       244\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.74      0.68      0.69      1600\n",
      "weighted avg       0.73      0.72      0.71      1600\n",
      "\n",
      "Accuracy: 0.724375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=20000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.75      0.55      0.63       231\n",
      "   happiness       0.59      0.96      0.73       294\n",
      "        hate       0.71      0.65      0.68       229\n",
      "     neutral       0.91      0.99      0.95       258\n",
      "     sadness       0.72      0.55      0.63       229\n",
      "    surprise       0.83      0.21      0.33       115\n",
      "       worry       0.71      0.73      0.72       244\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.74      0.66      0.67      1600\n",
      "weighted avg       0.73      0.72      0.70      1600\n",
      "\n",
      "Accuracy: 0.715625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=30000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.77      0.52      0.62       231\n",
      "   happiness       0.56      0.95      0.71       294\n",
      "        hate       0.74      0.64      0.69       229\n",
      "     neutral       0.85      1.00      0.92       258\n",
      "     sadness       0.74      0.55      0.63       229\n",
      "    surprise       0.86      0.16      0.26       115\n",
      "       worry       0.71      0.74      0.72       244\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.75      0.65      0.65      1600\n",
      "weighted avg       0.73      0.71      0.69      1600\n",
      "\n",
      "Accuracy: 0.705625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=40000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.78      0.45      0.57       231\n",
      "   happiness       0.55      0.96      0.70       294\n",
      "        hate       0.77      0.61      0.68       229\n",
      "     neutral       0.74      1.00      0.85       258\n",
      "     sadness       0.76      0.52      0.61       229\n",
      "    surprise       0.94      0.14      0.24       115\n",
      "       worry       0.72      0.73      0.73       244\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.75      0.63      0.63      1600\n",
      "weighted avg       0.73      0.69      0.66      1600\n",
      "\n",
      "Accuracy: 0.685625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=50000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.79      0.43      0.56       231\n",
      "   happiness       0.53      0.95      0.68       294\n",
      "        hate       0.79      0.58      0.66       229\n",
      "     neutral       0.67      1.00      0.80       258\n",
      "     sadness       0.79      0.49      0.61       229\n",
      "    surprise       0.88      0.13      0.23       115\n",
      "       worry       0.73      0.70      0.71       244\n",
      "\n",
      "    accuracy                           0.67      1600\n",
      "   macro avg       0.74      0.61      0.61      1600\n",
      "weighted avg       0.72      0.67      0.64      1600\n",
      "\n",
      "Accuracy: 0.66625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=60000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.81      0.39      0.53       231\n",
      "   happiness       0.52      0.94      0.67       294\n",
      "        hate       0.79      0.55      0.65       229\n",
      "     neutral       0.61      1.00      0.76       258\n",
      "     sadness       0.79      0.46      0.58       229\n",
      "    surprise       0.88      0.13      0.23       115\n",
      "       worry       0.72      0.68      0.70       244\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.73      0.59      0.59      1600\n",
      "weighted avg       0.71      0.65      0.62      1600\n",
      "\n",
      "Accuracy: 0.64625\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=70000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.82      0.35      0.49       231\n",
      "   happiness       0.50      0.89      0.64       294\n",
      "        hate       0.79      0.52      0.63       229\n",
      "     neutral       0.56      1.00      0.72       258\n",
      "     sadness       0.78      0.45      0.57       229\n",
      "    surprise       0.87      0.11      0.20       115\n",
      "       worry       0.73      0.66      0.69       244\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.72      0.57      0.56      1600\n",
      "weighted avg       0.70      0.62      0.60      1600\n",
      "\n",
      "Accuracy: 0.6225\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=80000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.85      0.32      0.47       231\n",
      "   happiness       0.50      0.87      0.64       294\n",
      "        hate       0.80      0.48      0.60       229\n",
      "     neutral       0.51      1.00      0.68       258\n",
      "     sadness       0.79      0.43      0.56       229\n",
      "    surprise       0.86      0.10      0.19       115\n",
      "       worry       0.73      0.65      0.69       244\n",
      "\n",
      "    accuracy                           0.60      1600\n",
      "   macro avg       0.72      0.55      0.54      1600\n",
      "weighted avg       0.70      0.60      0.58      1600\n",
      "\n",
      "Accuracy: 0.604375\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=90000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.86      0.32      0.46       231\n",
      "   happiness       0.51      0.85      0.63       294\n",
      "        hate       0.80      0.48      0.60       229\n",
      "     neutral       0.48      1.00      0.65       258\n",
      "     sadness       0.81      0.42      0.56       229\n",
      "    surprise       0.86      0.10      0.19       115\n",
      "       worry       0.72      0.63      0.67       244\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.72      0.54      0.54      1600\n",
      "weighted avg       0.70      0.59      0.57      1600\n",
      "\n",
      "Accuracy: 0.595\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=100000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.86      0.31      0.46       231\n",
      "   happiness       0.50      0.83      0.62       294\n",
      "        hate       0.81      0.46      0.58       229\n",
      "     neutral       0.46      1.00      0.63       258\n",
      "     sadness       0.79      0.41      0.54       229\n",
      "    surprise       0.83      0.09      0.16       115\n",
      "       worry       0.72      0.61      0.66       244\n",
      "\n",
      "    accuracy                           0.58      1600\n",
      "   macro avg       0.71      0.53      0.52      1600\n",
      "weighted avg       0.69      0.58      0.56      1600\n",
      "\n",
      "Accuracy: 0.5825\n",
      "\n",
      "\n",
      "\n",
      "for max_fearures=110000\n",
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.85      0.30      0.44       231\n",
      "   happiness       0.50      0.82      0.62       294\n",
      "        hate       0.81      0.46      0.58       229\n",
      "     neutral       0.44      1.00      0.62       258\n",
      "     sadness       0.80      0.41      0.54       229\n",
      "    surprise       0.82      0.08      0.14       115\n",
      "       worry       0.72      0.60      0.65       244\n",
      "\n",
      "    accuracy                           0.58      1600\n",
      "   macro avg       0.71      0.52      0.51      1600\n",
      "weighted avg       0.69      0.58      0.55      1600\n",
      "\n",
      "Accuracy: 0.575625\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for features in [int(k*10000) for k in [0.3,1,2,3,4,5,6,7,8,9,10,11]]:\n",
    "    bow_pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1, 2), max_features = features)),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    bow_pipeline.fit(X_train, y_train)\n",
    "    print(f\"for max_fearures={features}\")\n",
    "    model_evaluation(bow_pipeline)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8b452-6135-47a5-af56-0d513904890d",
   "metadata": {},
   "source": [
    "we can see that the results are worse than for ngram_range(1,1)<br><br>\n",
    "what about ngram_range=(2,2)? basically ensuring that we use two-word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80230cb7-1a00-4760-b11f-cc72f5bcd435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorizer_ngram(from_, to_,vectorizer):\n",
    "    bow_pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer(ngram_range=(from_, to_))),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    bow_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    num_features = len(bow_pipeline.named_steps['vectorizer'].vocabulary_)\n",
    "    print(\"this many features were found: \", num_features, \"\\n\")\n",
    "    \n",
    "    for features in [k for k in [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90]]:\n",
    "        number =features*num_features//100\n",
    "        bow_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer(ngram_range=(from_, to_), max_features = number)),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ])\n",
    "        \n",
    "        bow_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # print(f\"for max_fearures={features}%\")\n",
    "        # model_evaluation(bow_pipeline)[\"accuracy\"]\n",
    "        # print(\"\")\n",
    "        # print(\"\")\n",
    "        y_pred = bow_pipeline.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{number} features ({features}%) -> Accuracy: {acc}\")\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2854405f-49d0-4073-b5ad-580f48a101d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  104388 \n",
      "\n",
      "5219 features (5%) -> Accuracy: 0.478125\n",
      "\n",
      "10438 features (10%) -> Accuracy: 0.51875\n",
      "\n",
      "15658 features (15%) -> Accuracy: 0.5475\n",
      "\n",
      "20877 features (20%) -> Accuracy: 0.553125\n",
      "\n",
      "26097 features (25%) -> Accuracy: 0.559375\n",
      "\n",
      "31316 features (30%) -> Accuracy: 0.5475\n",
      "\n",
      "36535 features (35%) -> Accuracy: 0.54\n",
      "\n",
      "41755 features (40%) -> Accuracy: 0.535625\n",
      "\n",
      "46974 features (45%) -> Accuracy: 0.531875\n",
      "\n",
      "52194 features (50%) -> Accuracy: 0.53\n",
      "\n",
      "57413 features (55%) -> Accuracy: 0.528125\n",
      "\n",
      "62632 features (60%) -> Accuracy: 0.528125\n",
      "\n",
      "67852 features (65%) -> Accuracy: 0.523125\n",
      "\n",
      "73071 features (70%) -> Accuracy: 0.52375\n",
      "\n",
      "78291 features (75%) -> Accuracy: 0.52375\n",
      "\n",
      "83510 features (80%) -> Accuracy: 0.523125\n",
      "\n",
      "88729 features (85%) -> Accuracy: 0.520625\n",
      "\n",
      "93949 features (90%) -> Accuracy: 0.51625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ngram(2,2, CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b1043-9afc-4548-b6d7-01aa0c10cadd",
   "metadata": {},
   "source": [
    "we see that we perform better when we have singular words as features, so we will stick with:\n",
    "\n",
    "Pipeline([<br>\n",
    "            ('vectorizer', CountVectorizer(ngram_range=(1, 1), max_features = 3000)),<br>\n",
    "            ('classifier', MultinomialNB())<br>\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af3323",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Weighs word frequency by how common it is across all documents.<br>\n",
    "Multiplies two values:\n",
    "<li>TF (Term Frequency) = Frequency of a term in a document.\n",
    "<li>IDF (Inverse Document Frequency) = Inverse of how many documents contain the term.\n",
    "<br>\n",
    "Reduces the impact of common but less informative words, but ignores word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09123cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fun       0.93      0.38      0.54       231\n",
      "   happiness       0.49      0.95      0.65       294\n",
      "        hate       0.88      0.56      0.68       229\n",
      "     neutral       0.60      1.00      0.75       258\n",
      "     sadness       0.89      0.51      0.64       229\n",
      "    surprise       0.00      0.00      0.00       115\n",
      "       worry       0.74      0.72      0.73       244\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.65      0.59      0.57      1600\n",
      "weighted avg       0.69      0.65      0.62      1600\n",
      "\n",
      "Accuracy: 0.651875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michalwietecki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "model_evaluation(tfidf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff0197-3146-4c99-9a80-ae16833b645f",
   "metadata": {},
   "source": [
    "let's also see how does this vectorizer perform with different ngram_range/max_features values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "faf5a15c-5dde-4a72-9af3-e3f4560f26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  14101 \n",
      "\n",
      "705 features (5%) -> Accuracy: 0.523125\n",
      "\n",
      "1410 features (10%) -> Accuracy: 0.70875\n",
      "\n",
      "2115 features (15%) -> Accuracy: 0.755\n",
      "\n",
      "2820 features (20%) -> Accuracy: 0.75875\n",
      "\n",
      "3525 features (25%) -> Accuracy: 0.755625\n",
      "\n",
      "4230 features (30%) -> Accuracy: 0.753125\n",
      "\n",
      "4935 features (35%) -> Accuracy: 0.745625\n",
      "\n",
      "5640 features (40%) -> Accuracy: 0.735\n",
      "\n",
      "6345 features (45%) -> Accuracy: 0.726875\n",
      "\n",
      "7050 features (50%) -> Accuracy: 0.7175\n",
      "\n",
      "7755 features (55%) -> Accuracy: 0.70625\n",
      "\n",
      "8460 features (60%) -> Accuracy: 0.69875\n",
      "\n",
      "9165 features (65%) -> Accuracy: 0.69125\n",
      "\n",
      "9870 features (70%) -> Accuracy: 0.684375\n",
      "\n",
      "10575 features (75%) -> Accuracy: 0.676875\n",
      "\n",
      "11280 features (80%) -> Accuracy: 0.669375\n",
      "\n",
      "11985 features (85%) -> Accuracy: 0.66625\n",
      "\n",
      "12690 features (90%) -> Accuracy: 0.663125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ngram(1,1, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124109c3-5350-4943-bc99-6e3120d56a74",
   "metadata": {},
   "source": [
    "worse than for the first vectorizer, let's see with other ngram_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d784afa-7312-4bff-a42e-9a7f726213da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  118489 \n",
      "\n",
      "5924 features (5%) -> Accuracy: 0.694375\n",
      "\n",
      "11848 features (10%) -> Accuracy: 0.689375\n",
      "\n",
      "17773 features (15%) -> Accuracy: 0.66625\n",
      "\n",
      "23697 features (20%) -> Accuracy: 0.644375\n",
      "\n",
      "29622 features (25%) -> Accuracy: 0.638125\n",
      "\n",
      "35546 features (30%) -> Accuracy: 0.623125\n",
      "\n",
      "41471 features (35%) -> Accuracy: 0.609375\n",
      "\n",
      "47395 features (40%) -> Accuracy: 0.5975\n",
      "\n",
      "53320 features (45%) -> Accuracy: 0.5925\n",
      "\n",
      "59244 features (50%) -> Accuracy: 0.584375\n",
      "\n",
      "65168 features (55%) -> Accuracy: 0.578125\n",
      "\n",
      "71093 features (60%) -> Accuracy: 0.57375\n",
      "\n",
      "77017 features (65%) -> Accuracy: 0.57\n",
      "\n",
      "82942 features (70%) -> Accuracy: 0.56625\n",
      "\n",
      "88866 features (75%) -> Accuracy: 0.5625\n",
      "\n",
      "94791 features (80%) -> Accuracy: 0.560625\n",
      "\n",
      "100715 features (85%) -> Accuracy: 0.554375\n",
      "\n",
      "106640 features (90%) -> Accuracy: 0.550625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ngram(1,2, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6210350-1098-41ce-8111-7dc37e3170cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  104388 \n",
      "\n",
      "5219 features (5%) -> Accuracy: 0.474375\n",
      "\n",
      "10438 features (10%) -> Accuracy: 0.518125\n",
      "\n",
      "15658 features (15%) -> Accuracy: 0.5375\n",
      "\n",
      "20877 features (20%) -> Accuracy: 0.535625\n",
      "\n",
      "26097 features (25%) -> Accuracy: 0.539375\n",
      "\n",
      "31316 features (30%) -> Accuracy: 0.530625\n",
      "\n",
      "36535 features (35%) -> Accuracy: 0.5225\n",
      "\n",
      "41755 features (40%) -> Accuracy: 0.52\n",
      "\n",
      "46974 features (45%) -> Accuracy: 0.52125\n",
      "\n",
      "52194 features (50%) -> Accuracy: 0.51875\n",
      "\n",
      "57413 features (55%) -> Accuracy: 0.51625\n",
      "\n",
      "62632 features (60%) -> Accuracy: 0.515\n",
      "\n",
      "67852 features (65%) -> Accuracy: 0.515625\n",
      "\n",
      "73071 features (70%) -> Accuracy: 0.514375\n",
      "\n",
      "78291 features (75%) -> Accuracy: 0.515\n",
      "\n",
      "83510 features (80%) -> Accuracy: 0.51625\n",
      "\n",
      "88729 features (85%) -> Accuracy: 0.513125\n",
      "\n",
      "93949 features (90%) -> Accuracy: 0.51375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ngram(2,2, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e675b80-554c-4640-a2bb-e5f9148fe81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this many features were found:  285115 \n",
      "\n",
      "14255 features (5%) -> Accuracy: 0.49625\n",
      "\n",
      "28511 features (10%) -> Accuracy: 0.51\n",
      "\n",
      "42767 features (15%) -> Accuracy: 0.51875\n",
      "\n",
      "57023 features (20%) -> Accuracy: 0.511875\n",
      "\n",
      "71278 features (25%) -> Accuracy: 0.50625\n",
      "\n",
      "85534 features (30%) -> Accuracy: 0.501875\n",
      "\n",
      "99790 features (35%) -> Accuracy: 0.50375\n",
      "\n",
      "114046 features (40%) -> Accuracy: 0.500625\n",
      "\n",
      "128301 features (45%) -> Accuracy: 0.499375\n",
      "\n",
      "142557 features (50%) -> Accuracy: 0.495625\n",
      "\n",
      "156813 features (55%) -> Accuracy: 0.494375\n",
      "\n",
      "171069 features (60%) -> Accuracy: 0.489375\n",
      "\n",
      "185324 features (65%) -> Accuracy: 0.488125\n",
      "\n",
      "199580 features (70%) -> Accuracy: 0.4875\n",
      "\n",
      "213836 features (75%) -> Accuracy: 0.48875\n",
      "\n",
      "228092 features (80%) -> Accuracy: 0.484375\n",
      "\n",
      "242347 features (85%) -> Accuracy: 0.48375\n",
      "\n",
      "256603 features (90%) -> Accuracy: 0.48375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ngram(2,3, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1b4d5-120a-4106-8bb4-cc9ffbcdd76d",
   "metadata": {},
   "source": [
    "as we can see, approach with this particular vectorizer is just worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c6e79",
   "metadata": {},
   "source": [
    "## More complex, pretrained methods - for fun :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a15bc",
   "metadata": {},
   "source": [
    "## BERT (Deep Contextual Embeddings) - way more computationally intensive\n",
    "(Bidirectional Encoder Representations from Transformers)<br>\n",
    "Uses transformer layers to capture word meaning in context.\n",
    "<li>State-of-the-art for many NLP tasks, handles context well.\n",
    "<li>Computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a4bee41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def bert_embed(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "X_train_vec = bert_embed(list(X_train))\n",
    "X_test_vec = bert_embed(list(X_test))\n",
    "\n",
    "# Train and evaluate\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_vec, y_train_enc)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"\\nBERT Model Performance:\")\n",
    "print(classification_report(y_test_enc, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd2e22",
   "metadata": {},
   "source": [
    "## For further investigation we will use the more simple method, BOW\n",
    "BOW is very easy to understand and work with. Further in this document we will test other models than MultinominalNB. We will try to find a few models that conquer this task and try to ensamble than using various ensambling method (for example model voting). We will test Logistic Regression, Support Vector Machines (SVM), K-Nearest Neighbors (KNN) and some simple Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3982963-c7b0-4161-8795-5ff9b544989c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376993e6-e330-4f4b-b1ed-4d941af0a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7b542-59c4-4a47-ac51-60878690f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
